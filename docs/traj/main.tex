\documentclass[11pt]{scrartcl} % justified tufte-handout
%Gummi|065|=)
\title{\bfseries ValBal Altitude Control\\ and Trajectory Planning}
\subtitle{\Large Master document} % TODO maybe remove this

%\usepackage{classico}
\usepackage{microtype}
\author{Joan Creus-Costa\and John Dean}
%\date{}
\usepackage[margin=1.5in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{todonotes}\setlength{\marginparwidth}{1.3in}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{multicol}
\usepackage[bf]{caption}
\usepackage[sorting=none]{biblatex}
\bibliography{traj}

\captionsetup{format=plain}
\usetikzlibrary{calc}
\usetikzlibrary{shapes,arrows,positioning}

\usepackage{floatrow}
\begin{document}

\maketitle

\def\States{\mathcal{S}}
\def\Altitudes{\mathcal{H}}
\def\Velocities{\mathcal{V}}
\def\Lifts{\mathcal{L}}

\newcommand{\R}{\mathbb{R}}
\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}}
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}}
\newcommand{\probs}[3]{\paragraph{Problem #1} \textit{#2}
\begin{description}[labelwidth=.7cm,labelindent=0cm,leftmargin=0.9cm,align=left]
#3
\end{description}
}
\newcommand{\prob}[3]{\paragraph{Problem #1} \textit{#2}{#3}}
\newcommand{\prt}[1]{\subsection*{(#1)}}
\newcommand{\n}[1]{\mathrm{#1}}
\newcommand{\nb}[1]{\mathrm{\textbf{#1}}}
\newcommand{\mx}[2]{\left[ \begin{array}{#1} #2 \end{array} \right]}
\newcommand{\ig}[2]{\begin{center}\includegraphics[width=#1\linewidth]{#2}\end{center}}
\newcommand{\ls}[1]{\begin{lstlisting} #1 \end{lstlisting}} 
\newcommand{\conv}[1]{\mathrm{\textbf{conv}}\{ #1 \}}
\newcommand{\headfoot}[3]{
\pagestyle{fancy}
\lhead{#1}
\chead{#2}
\rhead{#3}
\lfoot{}
\cfoot{\thepage}
\rfoot{}
}

\newcommand{\ones}{\mathbf 1}
\newcommand{\reals}{{\mbox{\bf R}}}
\newcommand{\integers}{{\mbox{\bf Z}}}
\newcommand{\symm}{{\mbox{\bf S}}}  % symmetric matrices

\newcommand{\nullspace}{{\mathcal N}}
\newcommand{\range}{{\mathcal R}}
\newcommand{\Rank}{\mathop{\bf Rank}}
\newcommand{\Tr}{\mathop{\bf Tr}}
\newcommand{\diag}{\mathop{\bf diag}}
\newcommand{\card}{\mathop{\bf card}}
\newcommand{\rank}{\mathop{\bf rank}}
\newcommand{\prox}{\mathbf{prox}}

\newcommand{\Expect}{\mathop{\bf E{}}}
\newcommand{\Prob}{\mathop{\bf Prob}}
\newcommand{\Co}{{\mathop {\bf Co}}} % convex hull
\newcommand{\dist}{\mathop{\bf dist{}}}
\newcommand{\argmin}{\mathop{\rm argmin}}
\newcommand{\argmax}{\mathop{\rm argmax}}
\newcommand{\epi}{\mathop{\bf epi}} % epigraph
\newcommand{\Vol}{\mathop{\bf vol}}
\newcommand{\dom}{\mathop{\bf dom}} % domain
\newcommand{\intr}{\mathop{\bf int}}
\newcommand{\sign}{\mathop{\bf sign}}

\newcommand{\cf}{{\it cf.}}
\newcommand{\eg}{{\it e.g.}}
\newcommand{\ie}{{\it i.e.}}
\newcommand{\etc}{{\it etc.}}

\tableofcontents

\section*{Nomenclature}
\begin{tabular}{rl}
$h$ & altitude  \\
$v$ & vertical velocity\\
$\ell$ & net lift \\
$w_{\dot \ell}$ & disturbance on lift \\
$w_{v}$ & disturbance on the vertical velocity of the balloon (wind) \\
$\theta$ & parameters to differentiable trajectory planner, e.g. (altitude, setpoint) pairs\\
$V(\theta)$ & value function to be optimized for trajectory planning \\
$\hat V(\theta; \lambda)$ & stochastic evaluation of the value function under parametrized randomness $\lambda$ \\
$(u,v)$ & wind vector in longitude and latitude, respectively.`
\end{tabular}

\subsection*{Forward}

This paper is not written to be like a conventional conference or journal paper with the typical introduction to high altitude balloons or what the potential applications are. Rather, this document jumps right into technical details, as there was a lot to cover and we felt that at this point in time we should focus on just that, rather than the additional info to make it accessible to a wider audience.

In addition, some of the figures on this report are not of sufficient quality for publication. This is because many of them were taken from screen shots posted in SSI's slack while developing this project. At this stage, going back and generating good looking versions of them would take an unnecessary amount of time while not providing much benefit, as this is still meant to be a draft. 


\section{Altitude control}
\subsection{System dynamics}

High Altitude Balloons utilize a lifting gas that is lighter than air to produce a buoyant force to counteract the force of gravity on the balloon membrane and the payload. The buoyant force on the balloon minus the force of gravity on the balloon is refereed to as net lift, $\ell$. ValBal uses a valve system to vent lifting gas and a ballast system to drop small mass pellets, to change the net lift of the balloon. This net lift produces an acceleration on the system, causing the balloon to accelerate upwards or downwards until the force of drag on the system equals the net lift, at terminal velocity. Because the balloon accelerates to terminal velocity quickly after a change in net lift, the balloon's vertical velocity, $v$, can be approximately modeled as always traveling at terminal velocity.

While the force of drag on the balloon is nonlinear with respect to velocity, for the purposed of modeling and control, it can be linearized within a range of reasonable velocities. After doing so, the system dynamics can be simplified to:

\[ v(t) = k_d \ell \qquad \dot h(t) = v(t)\]

With $k_d$ being the linearized coefficient relating net lift to velocity. The valve and ballast system of can be seen as changes to the derivative of the net lift of the balloon, $\dot \ell$. For example, when the valve is open, $\dot \ell$ becomes negative as the balloon looses lift. In addition, the atmosphere is full of disturbances, so in the system dynamics we consider two other terms: $w_{\dot \ell}$ as the atmospheric disturbance on the lift rate, and $w_v$, as the atmospheric disturbance of velocity. For example, at night the balloon cools and looses lift, which is modeled as a negative $w_{\dot \ell}$, and vertical winds are modeled as a nonzero $w_v$. With these additions, the system dynamics become

\[ \dot v(t) = k_d(\dot \ell(t) + w_{\dot \ell}(t)) \qquad \dot h(t) = v(t) + w_v(t) \]

Using the following substitution we can write the a state-space representation of the system. 

\[x = \mx{c}{h \\ v} \qquad u = \dot \ell\]
\[\dot x = \mx{cc}{0 & 1 \\ 0 & 0}x + \mx{cc}{0 \\ k_d} u + \mx{c}{w_v \\ k_d w_{\dot \ell}}\]

%\newpage
\subsection{Control system}
\subsubsection{Overview}
The altitude control system has an unconventional objective for a feedback control system. On every ValBal flight, there is an essential trade-off between tracking closely to a target and system ballast use, as ballast is typically the endurance-limiting factor on a flight. Furthermore, this trade-off can not be usually be conveniently represented as a quadratic relationship between state errors and control inputs to allow for an LQG-style optimal control design. In addition, a more complex SMPC-based optimal control approach would not be feasible due to the constraints that the control law run on a low power embedded processor. Further more, the control objectives are typically given (or well-approximated by) a range of equally equally appealing altitudes, with a lower and upper bound. For instance, on an endurance flight with no location objectives, the lower bound is set by aircraft altitudes and the upper bound is set by latex degradation balloon latex degradation. 

As such a linear control law that is of the form $u = K \hat x$ for some $K \in \mathbf{R}^{1 \times 2}$, and a state estimate $\hat x$, would not be sufficient. Instead, a nested feedback loop structure is used, where an altitude loop commands a velocity loop which commands a change in lift, which allows for the easy addition of two key nonlinearities. The full control system structure is show in Figure~\ref{bd}.
\begin{figure}[h!]
\caption{Altitude control system block diagram}
\begin{center}
\begin{tikzpicture}[scale=2,
     block/.style = {draw, rectangle,node distance=1cm},
     input/.style = {node distance=1cm},
     output/.style = {node distance=1cm},
     arrow/.style={draw, -latex,node distance=2cm},
     pinstyle/.style = {pin edge={latex-, black,node distance=2cm}},
     sum/.style = {draw, circle, node distance=1cm},
     gain/.style = {regular polygon, regular polygon sides=3,draw, fill=white, text width=1em,
      inner sep=0mm, outer sep=0mm,
      shape border rotate=-90}
    ]
        
    \node [input] (hcmd) {$h_c$};
    \node [sum,right of=hcmd] (hsum) {};    
    \node [gain,right of=hsum, node distance=0.75cm] (K1) {$k_h$};
    \node [block, right of=K1] (N1) {$f_1$};
    \node [sum,right of=N1, node distance=1.2cm] (vsum) {};
    \node [input,above of=N1] (vlim) {$v_{\mathrm{lim}}$};
    \node [gain, right of=vsum,node distance=0.75cm] (K2) {$k_v$};
    \node [block, right of=K2] (N2) {$f_2$};
    \node [sum, right of=N2, node distance=2cm] (dlift) {};
    \node [input,above of=N2] (etol) {$\tau$};
    \node [input, above of=dlift] (ldist) {$w_{\dot \ell}$};
    \node [block, right of=dlift] (lint) {$\frac{k_d}{s}$};
    \node [sum, right of=lint] (velocity) {};
    \node [input, above of=velocity] (vdist) {$w_v$};
    \node [block, right of=velocity] (vint) {$\frac{1}{s}$};
    \node [output, right of=vint,node distance=1.4cm] (h) {$h$};
    \node [block, below of=vint,node distance=1.7cm] (H1) {$sH(s)$};
    \node [block, below right = .6 cm and -1.3 cm of dlift] (H2) {$k_d\left(\frac{1}{s}-H(s)\right)$};
    \node [sum, left of=H1,node distance=1.2cm] (fsum) {};

    \draw[->] (hcmd) -- (hsum) node [above left] {\scriptsize +};
    \draw[->] (hsum) -- (K1);
    \draw[->] (K1) -- (N1);
    \draw[->] (N1) -- node [above] {$v_c$} (vsum) node [above left] {\scriptsize +};
    \draw[->] (vsum) -- (K2);
    \draw[->] (K2) -- (N2);
    \draw[->,dashed] (etol) -- (N2);
    \draw[->,dashed] (vlim) -- (N1);
    \draw[->] (N2) -- node [above left] {$\dot \ell_c$} (dlift)  node [above left] {\scriptsize +};
    \draw[->] (ldist) -- (dlift) node [above right] {\scriptsize +};
    \draw[->] (dlift) -- (lint);
    \draw[->] (lint) -- (velocity) node [above left] {\scriptsize +};
    \draw[->] (vdist) -- (velocity) node [above right] {\scriptsize +};
    \draw[->] (velocity) -- (vint) node [above right] {};
    \draw[->] (vint) -- (h) node [above right] {};
    \draw  (h) ++ (-.3,0) -- ++(0,-1.15) coordinate (fb);
    \draw[->]  (h) ++ (-.3,0) |- (H1);
    \draw[->] (K2) ++ (0.8,0) |- (H2);
    \draw[->] (H1) -- (fsum) node [below right] {\scriptsize +};
    \draw[->] (H2) -| (fsum) node [above right] {\scriptsize +}; 
    \draw[->] (fsum) -| node [above left] {$\hat v$} (vsum) node [below left] {\scriptsize -};
    \draw[->] (fb) -| (hsum) node [below left] {\scriptsize -};
    \draw[thick,dotted] ($(dlift)+(-.3cm,.7cm)$) node [above right] {plant, $G(s)$} rectangle ($(vint)+(.3cm,-.3cm)$) ;
\end{tikzpicture}\\

\vspace{0.5cm}
\begin{tabular}{r l}
$H(s)$ &low-pass filter\\
$f_1(v\,;v_{\mathrm{lim}})$ & clamp on the velocity commanded by the altitude loop set by $v_{\mathrm{lim}}$ \\ 
$f_2(\dot \ell \, ; \tau)$ & deadband on the controller effort set by $\tau$ \\
$h_c$ & commanded altitude \footnotesize (set by Flight Controller) \\
$v_c$ & commanded velocity \footnotesize (output of position loop) \\
$\dot \ell_c$ & commanded change in lift per unit time  \footnotesize (output of velocity loop)\\
$w_{\dot \ell}$ & atmospheric disturbances that change balloon lift  \footnotesize (heating/cooling)\\
$w_v$ & atmospheric disturbances that change balloon velocity \footnotesize (turbulence)\\
$h$ & balloon altitude\\
$\hat v$ & estimate of velocity\\
\end{tabular}
\end{center}
\label{bd}
\end{figure}

\subsubsection{Nonlinearities}

The two non-linearities in the controller are given by $f_1$ and $f_2$. The first function $f_1(v\,;v_{\mathrm{lim}})$ is simply a clamping function that limits the velocity commanded by the altitude loop to $\pm v_{\mathrm{lim}}$. This prevents the controller from overreacting when it is far from it's command. The second non-linearity $f_2(\dot \ell \, ; \tau)$ is a deadband on the output of the controller. It is defined by 
%\begin{figure*}[h!]
\begin{center}
\begin{multicols}{2}
\null \vfill
\[
f_2(\dot \ell \, ; \tau) = \left\{\begin{array}{cc}
0 & |\dot \ell| < \tau \\ 
\mathrm{\textbf{sign}}(\dot \ell)(|\dot \ell| - \tau) & |\dot \ell| > \tau \\ 
\end{array}
\right.\] 
\vfill \null
\begin{tikzpicture}
\begin{axis}
[
width = 5cm,
height = 4cm,
scale = 1.4, 
xtick = {-1,0,1}, 
xticklabels = {$-\tau$,0,$\tau$}, 
ytick = {0}, 
ylabel = {\small $f_2$}, 
xlabel = {\small $\dot \ell$}, 
axis x line=middle, 
axis y line=middle,
xmin = -2.2, xmax = 2.2,
ymin = -2, ymax = 2,
every axis plot/.append style={thick}] 
  \addplot[domain=-1:1, samples=10] {0};
  \addplot[domain=1:2, samples=100] {x-1};
  \addplot[domain=-2:-1, samples=100] {x+1};
  \addplot[domain=-1.5:1.5, samples=100, style={very thin,dashed}] {x} node[above] {\tiny$f_2 =\dot \ell$};
\end{axis}
\end{tikzpicture}
\end{multicols}
\end{center}
%\vspace*{-1em}
%\end{figure*}

The parameter $\tau$ is set by $\tau = k_hk_ve_{\mathrm{tol}}$, where $e_{\n{tol}}$ is the steady-state error in altitude allowable by the controller. This means, that with $v=0$, the system can be at an altitude anywhere in the range $h = h_{\n{cmd}} \pm e_{\n{tol}}$, without the controller acting. The controller can then be thought of as having two bounds, $h_{\n{lower}},h_{\n{upper}}$ that are given by $h_{\n{lower}} = h_{\n{cmd}} - e_{\n{tol}}$ and $h_{\n{upper}} = h_{\n{cmd}} + e_{\n{tol}}$. As such, controller input commands can either be given in the form $(h_{\n{cmd}}, e_{\n{tol}})$ or $(h_{\n{lower}},h_{\n{upper}})$. The values are either set by the human flight controller commanding the system, or a trajectory planning algorithm (described in section \ref{TP}).

\subsubsection{Velocity estimator}

For control, it is important that we have a reasonable estimate of the vertical velocity of the balloon, $\hat v$. However, the atmosphere has a large amount of turbulence and waves, which have a dramatic impact on the short-term velocity of the balloon. For control on the altitude ranges that ValBal flies in, we do not care about these effects; what we actually care about is the component the velocity of the balloon that is due to the net lift. For example, it is possible for the balloon to be rising at 1~m/s, and still be neutrally buoyant, as it is simply floating atop a wave in the atmosphere. In this case, we would not want the controller to act to this in the same way it would to the balloon rising steadily at 1~m/s due to a positive net lift.

As a result, an estimator must be designed to calculate $\hat v$. A first order estimator such as a Kalman filter would suffice for this, if the noise on the velocity was Gaussian and uncorrelated in time. However, previous flight data and atmospheric literature \cite{waves} shows that this noise is dominated by large-amplitude waves at specific frequencies. Therefore, a second order low-pass filter, $H(s)$, is used to achieve better roll-off and reject the high frequency waves. In addition, actions of the controller are be integrated through the plan model to update the $\hat v$ estimate immediately after controller actions. The corner frequency of $H(s)$ is typically set around $($15~minutes$)^{-1}$ and is determined by looking at the spectral content of atmospheric waves in prior flight data.

\subsubsection{Choosing gains}

Choosing gains, $k_h$ and $k_v$, can be done through a linear second order system analysis of the system dynamic response. While the control system is non-linear, it is piecewise-linear, so for any given operating point a linear approximation remains valid.

The transfer function model for the system without nonlinearities is 
\[T(s) = \frac{k_h k_v k_d}{s^2 + k_v k_d s + k_h k_v k_d}.\]
The damping ratio is then given by $\zeta = \frac{1}{2}\sqrt{\frac{k_v k_d}{k_h}}$. Since in general minimal ballast usage is preferred over other performance metrics such as rise time, we want to ensure no overshoot in the step response of the controller. As such, we need to pick a gain ratio such that $\zeta \geq 1$. Assuming that we won't overshoot, we would prefer to have a minimal rise time, so we want the lowest damping ration that is greater than or equal to one, which would be one. However, $k_d$, is an estimated parameter we uncertainty associated with it, and since ensuring no overshoot is more important than minimizing rise time, we add in some margin. In practice, $\zeta = 1.2$ works well.

This gives use a ratio between gains, but not the magnitude of $k_h k_v$. However, picking the magnitude of the gains requires consideration of the deadband because, unlike a linear controller, a higher gain will not result in a closer tracking of $h_{\n{cmd}}$, that is set by the $e_{\n{tol}}$. Instead, the magnitude of the gains influences how aggressively the controller acts around the bounds. A high gain means that the controller will wait longer and act more aggressively near the bounds, and a lower gain means that it will act sooner but slower. In the limit of a small $k_h k_v$ and a small $e_{\n{tol}}$, the system will behave like a linear controller tracking $h_{\n{cmd}}$, and in the limit of a large $k_h k_v$, the system will behave like a bang-bang controller to command velocity to zero when the system reaches a boundary.

With no uncertainty in the system, high gain would result better performance as the system would wait until the last possible second to act. However, it would not be robust to noise in the system, measurement errors, or errors in the estimated parameters. While a robust controller analysis could be used to determine the best total gain magnitude, this is subject to realistic estimates of errors in the system which are rigorously defined. Instead, we model these errors in simulation, and tune this parameter using the simulation, described in the next section.


\subsection{Simulations}
Simulations are critical in the control system designs, as a means of testing new concepts, tuning parameters, checking flight-code for bugs, and for giving general intuition on the system, as each flight tests is expensive and it is not easy to radically change the control algorithm after the balloon is launched. While good control performance in simulation gives little guarantee on real-world performance, poor performance in simulation shows problems with the controller and misunderstandings of the system.

A simulation of the plan model shown in Figure~\ref{bd} is implemented in C++ (the architecture is described in depth in section \ref{arch}). Models for $w_{\dot \ell}$ and $w_{v}$ are determined by analysis of previous flight data. The noise models contain white noise, nightfall/sunrise effects, atmospheric waves, and terrain elevation effects.\footnote{Waves and terrain elevation have not been added yet but are currently being analyzed.}

A plot of an example simulation output is shown in \ref{lsim}. In this instance, the white noise on $w_{\dot \ell}$ was relatively small, as this simulation was a test of the controller's response to nightfall.
\begin{figure}[h]
\includegraphics[width=1\linewidth]{lsim.png}
\label{lsim}
\caption{Plot of a simulated ValBal flight, showing altitude (blue, left vertical axis) as a function time, along with various velocity terms (right vertical axis). Valve events (green vertical lines), ballast events (blue vertical lines), and controller bounds (gray horizontal lines) are shown.}
\end{figure}

\subsection{Flight results}
\todo[inline]{show plots of newer flights that used new controller}

\newpage
\section{Trajectory planning}
\label{TP}

\subsection{Introduction}

\todo[inline]{This section has gotten a bit long, but I wanted to lay out our reasoning for our choices. I only included three key citations to previous paper on high altitude balloon planning, as I only wanted to cite the most relevant work and be able to talk about each in a bit more detail, rather than just listing a bunch of tangentially-related work.}

ValBal has no direct control over its lateral movement around the globe, but rather is always drifting with the air currents of Earth's atmosphere. However, by changing the altitude that it flies at, it can choose different wind currents moving in a range of directions in a given column of air. In addition, being a low-cost and small balloon platform, ValBal's control authority is a finite resource that ultimately limits the duration of most missions. The high-level goal of trajectory planning is to come up with a set of altitudes that the balloon should fly at in order to achieve some mission outcome in the lateral trajectory of the balloon, conserving the amount of ballast used such that the flight does not end prematurely. Variations of this problem have been previously tackled in a number of a ways, primarily relying on either discretization of the state space to handle the nonlinear nature of the wind field, or linearizing a portion of of the wind field to simplify the processes of obtaining a control law. 

A recent method for station keeping was proposed in \cite{DBorn}, which utilized a receding horizon tree search with a discretized state space to find altitude sequences that would keep the balloon in one lateral location. This approach uses Gaussian Processes to model uncertainties in the wind field, and a novel method to discretize altitude ranges into currents of air moving in similar direction. In 2010, this problem was tackled for Montgolfiere balloon navigation on Titan \cite{wolf2010}, in which the surface of the planet was discretized into regions and a Markov decision process (MDP) was used to solve for minimum Time-to-Goal. Transition probabilities between discrete states were determined through a monte carlo method on the wind field distributions. 

In both of the above methods, the authors do not worry about minimizing the control action of the balloon. For large platforms with a regenerative method of adjusting lift this is sufficient, but for many objectives to be pursued by a ValBal, running out of ballast is a limiting factor on performance. As such, and trajectory planner for this platform must take ballast use into account. In a paper from 2003  \cite{das2003optimal}, the authors attempt to solve the problem of getting the balloon to a target location while minimizing fuel consumption of the balloon (in this case it's hot air balloon, in which fuel is analogous to ballast on valbal). They do so by solving the two-point boundary-value problem given by the Hamiltonian system of an optimal control problem that they formulate. However this formulation relies on linearizing the wind field in order to be tractable, which works in their case as they only attempt to solve the problem on instances on the order of kilometers in size, in which a linear approximation for the wind field works. The authors also to not account for uncertainty in the wind field.

For our problem, we must deal with the non-linear wind field as we operate over significant portions of the globe. In addition, we must account for not only uncertainty in the wind field, but also uncertainty in the altitude of the balloon, as it is impossible for the altitude controller to efficiently track a precise commanded altitude. Furthermore, the planner needs to keep track of at least one additional state: remaining ballast, as this effects how long the balloon can stay aloft. We also would like to retian high precision over states so that we can aim to fly the balloon with kilometers of desired destinations. This makes discretization of the state-space much more difficult that previous attempts, as we have more dimensions and desire fine precision.

So, we decided to take a different approach, using two key insights:
\begin{enumerate}
\item All dynamics of the system are fundamentally continuous and smooth due to the nature of wind being a continuous vector field.
\item The wind field of the atmosphere is highly structured, as it is the result of macro-scale thermodynamic and inertial effects on the globe. As such, large regions of the globe will have  winds all moving in the similar directions with slow changes
\end{enumerate}
The first point means that the dynamics of the system are easily integrable by simple Euler integration, as the second derivative of the dynamics are well-behaved. The second point leads us to hypothesize that most reasonably formed objective functions in the lateral location of the balloon will have much fewer local minima with respect to the altitude parameters than there are possible states of the system. \todo{I don't know how to say this well, but I think it's an extremely important point and is precisely the reason that it makes sense to solve the problem the way that we are solving it} That is to say, while we may care about the position of the balloon to a precision on the order of kilometers, the wind field structure likely results in there being only a relatively small number of locally quasi-convex regions in the space of control parameters. Consider these points in contrast to say a robot motion planning problem in a room with objects, which may be highly non-smooth and unstructured, where a search or value iteration on a discretized system often works well. 

So, our proposed solution to this problem is to use a fully continuous state and discretized time to perform a gradient-based optimization over the control parameters. We computing trajectories of the system in an analytically differentiable manner (implemented efficiently in software with automatic-differentiation). Expectations of the trajectory under the various forms of uncertainty are obtained through monte-carlo sampling and average. This formulation is both flexible to a range of different models for various effects on the altitude of the system, as well as computationally tractable for finding locally-optimal trajectories. It's major drawback is that it does not solve for a global optimum, but this mitigated by running the optmization from a set of random initial conditions, in attempt to find all local minima for a given scenario. 

We would then apply this in a Stochastic Model Predictive Control fashion, at each planning timestep of the system we take the current state of the balloon, optimize the control parameters entire duration or the mission, and then upload them to the balloon.

\subsection{Formulation}
\todo[inline]{This section needs to be reworked to be made consistent with the presentation. I also removed a large part as it is now covered in the introduction}
The physical system is represented by continuous states $s\in\States$ defined at discrete times $t_k=t_s + k \Delta t$, for $k=0,1,\dots$ In the case of ValBal, we can let $\States=\Altitudes\times\Lambda\times\Phi$, if we're considering altitudes, latitudes, and longitudes; we could extend this to include the ballast levels $\mathcal{B}$, or lifts $\Lifts$.

The altitude changes with respect to time according to the setpoint altitudes given to the control algorithm, with some randomness due to atmospheric noise. Latitude and longitude change according to Euler integration of the wind field, evaluated at every given time, altitude, and coordinates. Our goal is to find a control policy policy  to maximize some objection function, which might, for instance, be the total horizontal distance travelled.

This results in another advantage that comes from keeping the state space continuous. By picking some fixed set of parameters $\theta$ (that might be the setpoint altitudes and tolerances at various points of the flight) and integrating the trajectory as a function of those parameters, we can take the gradient of the cost function (that is a function of the trajectory) with respect to the parameters, and optimize our objective. We expand upon a formulation in the following section.

\subsubsection{Differentiable altitude trajectory}
Ultimately, our goal is to come up with some continuous and differentiable function $V(\theta)$ that gives the value of the objective function. However, in many instances, the value of the objective function will be related to the integration of the trajectory---e.g. distance travelled, or final longitude. This means that we need to come up with a formulation of the trajectory that depends on the optimization parameters and is differentiable with respect to them.

The parameters that form $\theta$ can, for instance, be a set of altitude waypoints defined at various points of the flight, or altitude tolerances at each of those points. If our state consisted only of altitudes, and we were to simply linearly interpolate between altitude waypoints $\theta_0, \theta_1, \dots$ (defined at $t^w_0, t^w_1, \dots$) we would find the parameters relevant to the current timestep $t_k$ such that $t^w_i < t_k < t^w_{i+1}$. Then we simply give:
\[h(t_k; \theta) = \theta_i + (t_k - t_i^w) \frac{\theta_{i+1}-\theta_i}{t_{i+1}^w - t^w_i}\]
which has a very simple derivative with respect to the optimization variables $\theta$. However, this assumes that we follow \emph{exactly} the trajectory defined by the optimization parameters. In reality, the value function $V(\theta)$ will be taken over an expectation ensemble of possible trajectories under noise.

In other words, our trajectory integration needs to output a distribution of possible states it might end up, while remaining differentiable. We introduce a parameter $\lambda$ that can be interpreted as a percentile of the noise distribution that a given trajectory is under. At the beginning of a rollout, a sequence $\lambda_0, \lambda_1, \dots$ is randomly generated such that the variation results in a noise level consistent with flight data. In the limit where all $\lambda$ are 0.5, the median trajectory is selected; in a more realistic simulation, the percentile would slowly fluctuate between smaller and larger numbers such that a particular rollout would be flying low or high respectively with respect to a noise-free simulation. For instance, in the scenario given above, we could introduce $\lambda(t)$ as a random walk bounded between $-500~\textrm{m}$ and $500~\textrm{m}$, defined between $t_0$ and $t_f$. Then our position is given by:
\[h(t_k; \theta) = \theta_i + (t_k - t_i^w) \frac{\theta_{i+1}-\theta_i}{t_{i+1}^w - t^w_i} + \lambda(t_k)\]
This allows us to consider a stochastic evaluation of our value function that remains differentiable.
\[\tilde V(\theta)=\sum_{\textrm{random}~\lambda} F(t_f, \lambda; \theta)\]

\subsubsection{Differentiable horizontal trajectory} \label{sec:horizontal}
The section above only handled altitude; however, the objective function for ValBal relies on maximizing spatial parameters, and not altitude. The horizontal integration needs to preserve differentiability to be able to compute a full gradient with respect to every optimization parameter. We use atmospheric data provided by \textsc{noaa} \cite{GFS} which, in particular, includes the velocity field $w(h, \lambda, \phi, t)\to(u, v)$, where $h$ is the altitude defined on a set of forecast altitudes;\footnote{The data from \textsc{noaa} is defined at barometric pressures, which can be mapped monotonically to altitude.} $\lambda$ and $\phi$ are the coordinates defined on a (not necessarily regular) grid of latitudes and longitudes;\footnote{Some models are more regular than others; for instance, NAM is defined on a rather annoying Lambert conformal grid.} $t$ is a forecast time (usually separated by 1 to 3 hours) and $(u, v)$ are the two horizontal components of wind.

For completely regular grids, bilinear interpolation will suffice. For irregular grids, a scheme such interpolation weighted by inverse distance $(\sum^K \alpha_i w_i)/(\sum^K \alpha_i)$ for the closest $K$ points would do the job. The weights of each nearby point are a function of altitude, latitude, and longitude; therefore, when we take the weighted sum, we preserve a differentiability path through the (differentiable) altitude. In other words, the final velocities $(u_k, v_k)$ are themselves a function of $\theta$, which we use to find the new coordinates:
\[x_{k+1} = x_k + u_k\Delta t\quad y_{k+1} = y_k + v_k\Delta t\]
and the conversion to $(\lambda_k, \phi_k)$ follows from a simple computation of spherical coordinates. 

The viability of this method, as well as the quality of \textsc{noaa} data can demonstrated by comparing the integration method and wind model to previous balloon flight data. To do so, we simulate a number of ValBal flights with added noise at the date and time of previous ValBal flights, using the same launch location and altitude profile. We then compare the results with the observed flight, to see that the observed flight matches the simulation. This comparison is shown in figure \ref{winds}.

\begin{figure}[h]
\includegraphics[width=0.45\linewidth]{winds.png}
\includegraphics[width=0.45\linewidth]{spain.png}
\caption{Comparison of real valbal flights (red) to valbal flights simulated using gfs data with added noise (blue)}
\label{winds}
\end{figure}

\subsubsection{Differentiable value function}
We can consider a variety of value functions. If we're trying to maximize the horizontal function, we can use the differentiable longitude computed in Section~\ref{sec:horizontal}. For a rollout of length $K$, the total value is the horizontal distance:
\begin{equation}
V = \sum_{k=0}^{K-1} u_k \Delta t\label{eqn:value}
\end{equation}
where $\Delta t$ is a constant that does not affect the result. Other valid objective functions could include the distance to a particular point:
\[V = \sum_{k=0}^{K-1} \lVert r_k - r_\text{target}\rVert\]


\subsubsection{Simple Example}
\todo[inline]{Joan can you write a text version of what you did for the slides}

\newpage
\subsection{Preliminary results}
\subsubsection{Certainty equivalent}
Before running the full stochastic gradient decent on the monte-carlo problem, we developed and tested the algorithm on certainty-equivalent simulation with no noise. In this experiment, we optimized a single starting trajectory, assuming that we had complete control over 20 altitude way points, with the balloon linearly interpolating between them. The results of such a test are shown in Figure~\ref{ce}. 

\begin{figure}[h!]
\floatbox[{\capbeside\thisfloatsetup{capbesideposition={right,top},capbesidewidth=6cm}}]{figure}[\FBwidth]
{\caption{Certainty equivalent optimization from a single trajectory of the total longitude traveled. Trajectories are depicted both in latitude vs longitude over a Mercator projection (top), and altitude vs time (middle). The launch site simulated was Hollister, California and flight endpoints are designated with a green star. Intermediate trajectories are shown in blue, with the final optimized result in red. A convergence plot of the objective function vs iteration number is shown (bottom).}\label{ce}}
{\includegraphics[width=1\linewidth]{certaintyeq.png}}
\end{figure}

We can see from this Figure~\ref{ce} that the optimization behaves as expected. The final longitude slowly moves forward each iteration, until it reaches a local extremum. The path of green points over the map---the endpoints of each intermediate trajectory---always moves to the right as iteration number increases. Running a thousand iterations of certainty equivalent optimization on a 100 hour flight as in the example takes well under a second on our hardware.

\subsubsection{Monte-Carlo runs}

To run our first test of this formulation, we opted to utilize the traditional Model Predictive Control approach, in which we optimize an open-loop policy over a finite horizon. In flight, this optimization would be run repeatedly as the balloon flies, using the most recently observed system state to optimize new trajectories, forming a feedback control law. 

Results of this method on a sample of \textsc{noaa} analysis wind data are shown in Figure~\ref{openloop}.
\begin{figure}[h]
\includegraphics[width=\linewidth]{datasheetfig.png}
\caption{Example result of optimizing an open loop trajectory. The initial settings were a 13.5km setpoint and a 0.75km tolerance (red), while the optimized trajectory shows both changing setpoints and tolerances (blue). The dark blue line gives an example possible altitude profile from the many possible altitudes profiles given the command settings}
\label{openloop}
\end{figure}

We notice a few things from this result. First, we note that in this particular scenario the initial commands resulted in a large variation in the resulting flight path. This was due to large changes in wind direction within the command tolerance over the Atlantic Ocean. We see that in the optimized open-loop trajectory, policies are picked such that there is not much variation in the resulting outcome. 
\subsubsection{Location-feedback altitude policy}
\todo[inline]{Still working through implementation}
\subsubsection{Flight tests}
\todo[inline]{As we don't have quality plots from the last flight, we didn't write up things about it in this section as I expect to have a much better opportunity to do so next quarter. For plots, see the presentation slides we made about it.}


\newpage
\section{Architecture}
\label{arch}
In this section we describe the architecture behind the simulations and trajectory optimization. It involves a complex pipeline, that involves fetching atmospheric data, a modular and fast simulation engine, and provisions for simulating with real flight code. It is mostly written more than two thousand lines of C++ and Python.

The core of the simulator is written in C++. This allows for extremely fast simulations; when performing direct rollouts, it can compute hundreds of thousands of three-day ValBal trajectories per second on a 6-core machine. The code is designed to be modular; one can easily use different objective functions (horizontal distance, distance to a given target\dots), different optimization methods (vanilla gradient descent, Adagrad, Adam\dots), various differentiable controllers (uniform distribution, approximate Lasagna, differentiable Lasagna\dots), and so on.

Having been designed with optimization in mind, another key feature of the simulation codebase is the formulation in terms of C++ templates, that allow the compiler to, from a single codebase, generate code that either merely computes rollouts of the trajectories, or keeps track of the gradients leading to the final objective function. The latter uses \emph{automatic differentation}, the same algorithm used in the training of large neural networks. It keeps track of the computation graph and derivative at each node; once the final objective function is computed (say, the final longitude), the gradient is propagated backwards to each parameter, and some first-order optimization method is used to update the parameters. By using the Adept library, the parametrized codebase can be specialized to use Adept's differentiable floating point type, that keeps track of the computation graph. Doing so incurs an overhead, of about 5 to 10$\times$, but is able to provide the exact gradient of the objective with respect to the parameters, in a much easier way than direct numeric differentiation, and without having separate code paths for direct evaluation and gradient evaluation.

We also built several Python scripts to fetch the data and process the results. We can retrieve wind data from either the Global Forecast System (\textsc{gfs}) model from \textsc{noaa}, or the European \textsc{ecmwf} model. We preprocess the data, that comes in \textsc{grib} files, into binary files that are loaded directly by C++. This is key to the speed of the C++ codebase, by using the \texttt{mmap} system call from Linux, the data will end up cached in the comparatively faster RAM, and wind table lookups require merely the computation of an offset (as opposed to searching through a database, with various levels of indirection). In particular, we only store relevant variables at the altitudes ValBal normally flies, in order to save space and improve cache performance. Several Python scripts are used to plot the trajectories found by the C++ script (saved to a binary file) using the Matplotlib library.

\newpage
\printbibliography

\end{document}

